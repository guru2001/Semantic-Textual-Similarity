{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe,FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 23\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "'batch_size' : 128,\n",
    "'char_emb_dim' : 20,\n",
    "'char_emb_hs' : 50,\n",
    "'data' :'snli',\n",
    "'dropout' : 0.1,\n",
    "'eps' : 15,\n",
    "'gpu' : 2,\n",
    "'hs' : 100,\n",
    "'lr' : 1e-3,\n",
    "'max_sent_len' : -1,\n",
    "'num_perspective' : 20,\n",
    "'print_freq' : 500,\n",
    "'word_emb_dim' : 300,\n",
    "'val_size' : 0.1,\n",
    "'test_size' : 0.1,\n",
    "'model_time' : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNLI_Data():\n",
    "    TEXT = data.Field(batch_first=True, tokenize=word_tokenize, lower=True)\n",
    "    LABEL = data.Field(sequential=False, unk_token=None)\n",
    "    \n",
    "    train, dev, test = datasets.SNLI.splits(TEXT, LABEL)\n",
    "    TEXT.build_vocab(train, dev, test,vectors=GloVe(name='840B', dim=300), unk_init=torch.Tensor.zero_)\n",
    "    LABEL.build_vocab(train)\n",
    "    sort_key = lambda x: data.interleave_keys(len(x.q1), len(x.q2))\n",
    "\n",
    "    train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test),\\\n",
    "                                    batch_sizes=[params['batch_size']] * 3,\n",
    "                                   device=params['gpu'])\n",
    "    iterator = {\n",
    "        'train_iter' : train_iter,\n",
    "        'dev_iter' : dev_iter,\n",
    "        'test_iter' : test_iter\n",
    "    }\n",
    "    \n",
    "    return iterator, TEXT, LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator, TEXT, LABEL = SNLI_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Char_Vocab(TEXT):\n",
    "    max_word_len = 0\n",
    "    for word in TEXT.vocab.itos:\n",
    "        max_word_len = max(len(word), max_word_len)\n",
    "    char_vocab = {'': 0}\n",
    "    characterized_vectors = []\n",
    "    for word in TEXT.vocab.itos:\n",
    "        chars = []\n",
    "        if word == '<unk>' or word == '<pad>':\n",
    "            chars = (max_word_len*[0])\n",
    "        else:\n",
    "            for c in word:\n",
    "                if c not in char_vocab:\n",
    "                    char_vocab[c] = len(char_vocab)\n",
    "                chars.append(char_vocab[c])\n",
    "            \n",
    "            chars.extend([0]*(max_word_len - len(word)))\n",
    "        characterized_vectors.append(chars)\n",
    "        \n",
    "    return characterized_vectors, char_vocab, max_word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characterized_vectors, char_vocab, max_word_len = Build_Char_Vocab(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characterize(batch):\n",
    "    batch = batch.data.cpu().numpy().astype(int).tolist()\n",
    "    return [[characterized_vectors[w] for w in words] for words in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  {\n",
    "    'TEXT' : TEXT,\n",
    "    'LABEL' : LABEL,\n",
    "    'iterator' : iterator,\n",
    "    'characterized_vectors' : characterized_vectors,\n",
    "    'char_vocab' : char_vocab,\n",
    "    'max_word_len' : max_word_len,\n",
    "    'word_vocab_size': len(TEXT.vocab),\n",
    "    'char_vocab_size' : len(char_vocab),\n",
    "    'class_size' : len(LABEL.vocab)\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIMPM(nn.Module):\n",
    "    def __init__(self, params, data):\n",
    "        super(BIMPM, self).__init__()\n",
    "\n",
    "        self.params = params\n",
    "        self.data = data\n",
    "\n",
    "        self.d = self.params['word_emb_dim'] + self.params['char_emb_hs']\n",
    "        self.l = self.params['num_perspective']\n",
    "\n",
    "        \n",
    "        self.char_emb = nn.Embedding(self.data['char_vocab_size'], self.params['char_emb_dim'], padding_idx=0)\n",
    "        self.word_emb = nn.Embedding(self.data['word_vocab_size'], self.params['word_emb_dim'])\n",
    "        self.word_emb.weight.data.copy_(data['TEXT'].vocab.vectors)\n",
    "        self.word_emb.weight.requires_grad = False\n",
    "        self.char_LSTM = nn.LSTM(input_size=self.params['char_emb_dim'],hidden_size=self.params['char_emb_hs'],batch_first=True,num_layers=1,bidirectional=False)\n",
    "\n",
    "        \n",
    "      \n",
    "        self.context_layer_LSTM = nn.LSTM(input_size=self.d, hidden_size=self.params['hs'],num_layers=1, \\\n",
    "            bidirectional=True,batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.W1 = nn.Parameter(torch.rand(self.l, self.params['hs']))\n",
    "        self.W2 = nn.Parameter(torch.rand(self.l, self.params['hs']))\n",
    "\n",
    "\n",
    "        \n",
    "        self.aggregation_layer_LSTM = nn.LSTM(input_size=self.l * 2,hidden_size=self.params['hs'],num_layers=1,\\\n",
    "            bidirectional=True,batch_first=True)\n",
    "\n",
    "\n",
    "        \n",
    "        self.pred_fc1 = nn.Linear(self.params['hs'] * 4, self.params['hs'] * 2)\n",
    "        self.pred_fc2 = nn.Linear(self.params['hs'] * 2, self.data['class_size'])\n",
    "\n",
    "        self.init_BIMPM()\n",
    "        \n",
    "    def Initialize_LSTM(self,LSTM, rev):\n",
    "        \n",
    "        nn.init.kaiming_normal_(LSTM.weight_ih_l0)\n",
    "        nn.init.constant_(LSTM.bias_ih_l0, val=0)\n",
    "        nn.init.orthogonal_(LSTM.weight_hh_l0)\n",
    "        nn.init.constant_(LSTM.bias_hh_l0, val=0)\n",
    "        \n",
    "        if rev == 1:\n",
    "            \n",
    "            nn.init.kaiming_normal_(LSTM.weight_ih_l0_reverse)\n",
    "            nn.init.constant_(LSTM.bias_ih_l0_reverse, val=0)\n",
    "            nn.init.orthogonal_(LSTM.weight_hh_l0_reverse)\n",
    "            nn.init.constant_(LSTM.bias_hh_l0_reverse, val=0)\n",
    "\n",
    "        return LSTM\n",
    "\n",
    "\n",
    "    def init_BIMPM(self):\n",
    "       \n",
    "        nn.init.uniform_(self.char_emb.weight, -0.005, 0.005)\n",
    "        self.char_emb.weight.data[0].fill_(0)\n",
    "        nn.init.uniform_(self.word_emb.weight.data[0], -0.1, 0.1)\n",
    "        self.char_LSTM = self.Initialize_LSTM(self.char_LSTM, 0)\n",
    "\n",
    "\n",
    "        self.context_layer_LSTM = self.Initialize_LSTM(self.context_layer_LSTM, 1)\n",
    "\n",
    "\n",
    "        nn.init.kaiming_normal_(self.W1)\n",
    "        nn.init.kaiming_normal_(self.W2)\n",
    "\n",
    "\n",
    "        self.aggregation_layer_LSTM = self.Initialize_LSTM(self.aggregation_layer_LSTM, 1)\n",
    "\n",
    "        \n",
    "        nn.init.uniform_(self.pred_fc1.weight, -0.005, 0.005)\n",
    "        nn.init.constant_(self.pred_fc1.bias, val=0)\n",
    "        nn.init.uniform_(self.pred_fc2.weight, -0.005, 0.005)\n",
    "        nn.init.constant_(self.pred_fc2.bias, val=0)\n",
    "\n",
    "    def dropout(self, v):\n",
    "        return F.dropout(v, p=self.params['dropout'], training=self.training)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        def match_fn(v1, v2, w):\n",
    "            seq_len = v1.size(1)\n",
    "            w = w.transpose(1, 0).unsqueeze(0).unsqueeze(0)\n",
    "            v1 = w * torch.stack([v1] * self.l, dim=3)\n",
    "            if len(v2.size()) == 3:\n",
    "                v2 = w * torch.stack([v2] * self.l, dim=3)\n",
    "            else:\n",
    "                v2 = w * torch.stack([torch.stack([v2] * seq_len, dim=1)] * self.l, dim=3)\n",
    "\n",
    "            m = F.cosine_similarity(v1, v2, dim=2)\n",
    "\n",
    "            return m\n",
    "\n",
    "\n",
    "        p = self.word_emb(kwargs['p'])\n",
    "        h = self.word_emb(kwargs['h'])\n",
    "\n",
    "        seq_len_p = kwargs['char_p'].size(1)\n",
    "        seq_len_h = kwargs['char_h'].size(1)\n",
    "\n",
    "        char_p = kwargs['char_p'].view(-1, data['max_word_len'])\n",
    "        char_h = kwargs['char_h'].view(-1, data['max_word_len'])\n",
    "\n",
    "        _, (char_p, _) = self.char_LSTM(self.char_emb(char_p))\n",
    "        _, (char_h, _) = self.char_LSTM(self.char_emb(char_h))\n",
    "\n",
    "        char_p = char_p.view(-1, seq_len_p, self.params['char_emb_hs'])\n",
    "        char_h = char_h.view(-1, seq_len_h, self.params['char_emb_hs'])\n",
    "\n",
    "        p = torch.cat([p, char_p], dim=-1)\n",
    "        h = torch.cat([h, char_h], dim=-1)\n",
    "\n",
    "        p = self.dropout(p)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        con_p, _ = self.context_layer_LSTM(p)\n",
    "        con_h, _ = self.context_layer_LSTM(h)\n",
    "\n",
    "        con_p = self.dropout(con_p)\n",
    "        con_h = self.dropout(con_h)\n",
    "\n",
    "        con_p_fw, con_p_bw = torch.split(con_p, self.params['hs'], dim=-1)\n",
    "        con_h_fw, con_h_bw = torch.split(con_h, self.params['hs'], dim=-1)\n",
    "\n",
    "\n",
    "        mv_p_full_fw = match_fn(con_p_fw, con_h_fw[:, -1, :], self.W1)\n",
    "        mv_p_full_bw = match_fn(con_p_bw, con_h_bw[:, 0, :], self.W2)\n",
    "        mv_h_full_fw = match_fn(con_h_fw, con_p_fw[:, -1, :], self.W1)\n",
    "        mv_h_full_bw = match_fn(con_h_bw, con_p_bw[:, 0, :], self.W2)\n",
    "        \n",
    "        mv_p = torch.cat(\n",
    "            [mv_p_full_fw,mv_p_full_bw], dim=2)\n",
    "        mv_h = torch.cat(\n",
    "            [mv_h_full_fw,mv_h_full_bw], dim=2)\n",
    "\n",
    "        mv_p = self.dropout(mv_p)\n",
    "        mv_h = self.dropout(mv_h)\n",
    "\n",
    "        _, (agg_p_last, _) = self.aggregation_layer_LSTM(mv_p)\n",
    "        _, (agg_h_last, _) = self.aggregation_layer_LSTM(mv_h)\n",
    "\n",
    "        x = torch.cat(\n",
    "            [agg_p_last.permute(1, 0, 2).contiguous().view(-1, self.params['hs'] * 2),\n",
    "             agg_h_last.permute(1, 0, 2).contiguous().view(-1, self.params['hs'] * 2)], dim=1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.tanh(self.pred_fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pred_fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, params, data, mode=1):\n",
    "  \n",
    "    if mode == 0:\n",
    "        iterator = iter(data['iterator']['dev_iter'])\n",
    "    else:\n",
    "        iterator = iter(data['iterator']['test_iter'])\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    acc, loss, size = 0, 0, 0\n",
    "\n",
    "    \n",
    "    for batch in iterator:\n",
    "        s1, s2 = 'premise', 'hypothesis'\n",
    "        \n",
    "        s1, s2 = getattr(batch, s1), getattr(batch, s2)\n",
    "        \n",
    "        if params['gpu'] > -1:\n",
    "            s1 = s1.cuda(params['gpu'])\n",
    "            s2 = s2.cuda(params['gpu'])\n",
    "\n",
    "        kwargs = {'p': s1, 'h': s2}\n",
    "\n",
    "        char_p = Variable(torch.LongTensor(characterize(s1)))\n",
    "        char_h = Variable(torch.LongTensor(characterize(s2)))\n",
    "\n",
    "        if params['gpu'] > -1:\n",
    "            char_p = char_p.cuda(params['gpu'])\n",
    "            char_h = char_h.cuda(params['gpu'])\n",
    "\n",
    "        kwargs['char_p'] = char_p\n",
    "        kwargs['char_h'] = char_h\n",
    "\n",
    "        pred = model(**kwargs)\n",
    "\n",
    "        batch_loss = criterion(pred, batch.label.cuda(params['gpu']))\n",
    "        loss += batch_loss.data.item()\n",
    "\n",
    "        _, pred = pred.max(dim=1)\n",
    "        acc += (pred == batch.label.cuda(params['gpu'])).sum().float()\n",
    "        size += len(pred)\n",
    "\n",
    "    acc /= size\n",
    "    acc = acc.cpu().data.item()\n",
    "    return loss, acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params, data):\n",
    "    model = BIMPM(params, data)\n",
    "\n",
    "    if params['gpu'] > -1:\n",
    "        model.cuda(params['gpu'])\n",
    "\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.AdamW(parameters, lr=params['lr'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    loss, last_epoch = 0, -1\n",
    "    max_dev_acc, max_test_acc = 0, 0\n",
    "\n",
    "    iterator = data['iterator']['train_iter']\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    epochs = params['eps']\n",
    "    \n",
    "    while epochs != 0:\n",
    "        epochs -= 1\n",
    "        epoch_loss = 0\n",
    "#         cnt_batches = 0\n",
    "        print(\"Epoch: %s\" %(params['eps']- epochs))\n",
    "        for i, batch in enumerate(iterator):\n",
    "#             cnt_batches += 1\n",
    "            s1, s2 = 'premise', 'hypothesis'\n",
    "\n",
    "\n",
    "            s1, s2 = getattr(batch, s1), getattr(batch, s2)\n",
    "\n",
    "            if params['max_sent_len'] >= 0:\n",
    "                if s1.size()[1] > params['max_sent_len']:\n",
    "                    s1 = s1[:, :params['max_sent_len']]\n",
    "                if s2.size()[1] > params['max_sent_len']:\n",
    "                    s2 = s2[:, :params['max_sent_len']]\n",
    "\n",
    "            if params['gpu'] > -1:\n",
    "                s1 = s1.cuda(params['gpu'])\n",
    "                s2 = s2.cuda(params['gpu'])\n",
    "\n",
    "            kwargs = {'p': s1, 'h': s2}\n",
    "\n",
    "            char_p = Variable(torch.LongTensor(characterize(s1)))\n",
    "            char_h = Variable(torch.LongTensor(characterize(s2)))\n",
    "\n",
    "            if params['gpu'] > -1:\n",
    "                char_p = char_p.cuda(params['gpu'])\n",
    "                char_h = char_h.cuda(params['gpu'])\n",
    "\n",
    "            kwargs['char_p'] = char_p\n",
    "            kwargs['char_h'] = char_h\n",
    "\n",
    "            pred = model(**kwargs)\n",
    "\n",
    "            pred = pred.cuda(params['gpu'])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss = criterion(pred, batch.label.cuda(params['gpu']))\n",
    "            loss += batch_loss.data.item()\n",
    "            epoch_loss += batch_loss.data.item()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % params['print_freq'] == 0:\n",
    "                dev_loss, dev_acc = test(model, params, data, mode=0)\n",
    "                test_loss, test_acc = test(model, params, data)\n",
    "                c = (i + 1) // params['print_freq']\n",
    "\n",
    "                print('train loss: ',loss, 'dev loss: ',dev_loss,'test loss: ', test_loss, 'dev acc: ', dev_acc , 'test acc: ', test_acc)\n",
    "\n",
    "                if dev_acc > max_dev_acc:\n",
    "                    max_dev_acc = dev_acc\n",
    "                    max_test_acc = test_acc\n",
    "                    if not os.path.exists('saved_models'):\n",
    "                        os.makedirs('saved_models')\n",
    "                    torch.save(model.state_dict(), f'../models/BIBPM_snli.pt')\n",
    "                loss = 0\n",
    "                model.train()\n",
    "                \n",
    "        train_loss.append(epoch_loss)\n",
    "        \n",
    "        dev_loss, dev_acc = test(model, params, data, mode=0)\n",
    "        val_loss.append(dev_loss)\n",
    "        model.train()\n",
    "\n",
    "    print('max dev acc:', max_dev_acc, 'max test acc: ', max_test_acc)\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params['model_time'] = strftime('%H:%M:%S', gmtime())\n",
    "print('training start!')\n",
    "train_loss, val_loss = train(params, data)\n",
    "\n",
    "print('training finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, precision_recall_fscore_support, f1_score,confusion_matrix,plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss, val_loss):\n",
    "    \n",
    "    X = [i for i in range(1,params['eps']+1)]\n",
    "    \n",
    "    plt.plot(X,train_loss)\n",
    "    plt.ylabel('train-loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(X,val_loss)\n",
    "    plt.ylabel('val-loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(params, data):\n",
    "    model = BIMPM(params, data)\n",
    "    model.load_state_dict(torch.load('../models/BIBPM_snli.pt'))\n",
    "\n",
    "    if params['gpu'] > -1:\n",
    "        model.cuda(params['gpu'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1(model, params, data):\n",
    "\n",
    "    iterator = iter(data['iterator']['test_iter'])\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    acc, loss, size = 0, 0, 0\n",
    "\n",
    "    actual = list()\n",
    "    preds = list()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        s1, s2 = 'premise', 'hypothesis'\n",
    "        \n",
    "        s1, s2 = getattr(batch, s1), getattr(batch, s2)\n",
    "        \n",
    "        if params['gpu'] > -1:\n",
    "            s1 = s1.cuda(params['gpu'])\n",
    "            s2 = s2.cuda(params['gpu'])\n",
    "\n",
    "        kwargs = {'p': s1, 'h': s2}\n",
    "\n",
    "        char_p = Variable(torch.LongTensor(characterize(s1)))\n",
    "        char_h = Variable(torch.LongTensor(characterize(s2)))\n",
    "\n",
    "        if params['gpu'] > -1:\n",
    "            char_p = char_p.cuda(params['gpu'])\n",
    "            char_h = char_h.cuda(params['gpu'])\n",
    "\n",
    "        kwargs['char_p'] = char_p\n",
    "        kwargs['char_h'] = char_h\n",
    "\n",
    "        pred = model(**kwargs)\n",
    "        \n",
    "\n",
    "        actual.extend(batch.label)\n",
    "        preds.extend(pred.detach().cpu())\n",
    "\n",
    "        batch_loss = criterion(pred, batch.label.cuda(params['gpu']))\n",
    "        loss += batch_loss.data.item()\n",
    "\n",
    "        _, pred = pred.max(dim=1)\n",
    "        acc += (pred == batch.label.cuda(params['gpu'])).sum().float()\n",
    "        size += len(pred)\n",
    "\n",
    "    acc /= size\n",
    "    acc = acc.cpu().data.item()\n",
    "    \n",
    "\n",
    "    return loss, acc, preds, actual \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(params, data)\n",
    "loss , acc , preds, actual = test1(model, params, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentences(sen):\n",
    "    sentence = \"\"\n",
    "    for i in sen:\n",
    "        if(TEXT.vocab.itos[i] != '<pad>'):\n",
    "            sentence += TEXT.vocab.itos[i] + \" \"\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(data['iterator']['test_iter'])\n",
    "sentences1 = []\n",
    "sentences2 = []\n",
    "\n",
    "for batch in iterator:\n",
    "        s1, s2 = 'premise', 'hypothesis'\n",
    "        \n",
    "        s1, s2 = getattr(batch, s1), getattr(batch, s2)\n",
    "        \n",
    "        for i in range(0,len(s1)):\n",
    "            sentences1.append(decode_sentences(s1[i]))\n",
    "            sentences2.append(decode_sentences(s2[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = preds\n",
    "predicted_classes = []\n",
    "for ten in temp:\n",
    "    predicted_classes.append(torch.argmax(ten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(actual)):\n",
    "    if(actual[i] != predicted_classes[i]):\n",
    "        print(\"premise: \",sentences1[i],\"hypothesis: \",sentences2[i],\"actual_label: \" ,actual[i].tolist() ,\"predicted_label: \",predicted_classes[i].tolist())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_measure, _ = precision_recall_fscore_support(actual, predicted_classes, average='macro')\n",
    "\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"f1_score:\",f1_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(actual, predicted_classes)\n",
    "print(\"Confusion Matrix:\\n\",conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(conf, annot=True); #annot=True to annotate cells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
